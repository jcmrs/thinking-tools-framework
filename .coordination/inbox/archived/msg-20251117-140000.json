{
  "id": "msg-20251117-140000",
  "from": "coordinator",
  "to": "project-instance",
  "type": "directive",
  "priority": "high",
  "timestamp": "2025-11-17T14:00:00Z",
  "content": "Layer 5 Enhancements: Progressive Disclosure + Token Telemetry\n\nEXCELLENT work on the FastMCP refactoring! 45% code reduction, cleaner API, resources/prompts added - all perfect.\n\nNow let's add the two research-backed enhancements that will provide immediate value:\n\n═══════════════════════════════════════════════════════════\nENHANCEMENT 1: FILESYSTEM-BASED PROGRESSIVE DISCLOSURE\n═══════════════════════════════════════════════════════════\n\nRESEARCH FINDING: Anthropic's code-execution-with-MCP demonstrates 98.7% token reduction by organizing MCP tools as filesystem structure instead of loading all schemas upfront.\n\nCURRENT SITUATION:\n- 9 tools × ~500 tokens/schema = 4,500 tokens on list_tools()\n- Even if client uses 2-3 tools, all 9 schemas loaded\n- Will scale poorly as we grow to 50+ tools\n\nSOLUTION: Progressive Tool Discovery (65% token savings)\n\nSTEP 1: Reorganize YAML Files by Category\n```\nexamples/\n├── metacognition/\n│   ├── think_aloud.yaml\n│   ├── fresh_eyes.yaml\n│   ├── perspective_shift.yaml\n│   └── second_opinion.yaml\n├── code_quality/\n│   ├── code_review.yaml\n│   └── refactor_analysis.yaml\n└── collaboration/\n    ├── handoff.yaml\n    ├── context_sync.yaml\n    └── deliverable.yaml\n```\n\nSTEP 2: Add MCP Resource for Category Discovery\n```python\n@mcp.resource(\"thinking-tools://discover\")\ndef discover_tool_categories() -> Dict[str, List[str]]:\n    \"\"\"List available tool categories and their tools.\n    \n    Enables progressive disclosure - client explores categories\n    and loads specific tools on-demand.\n    \"\"\"\n    categories = {}\n    examples_dir = Path(\"examples\")\n    \n    for category_dir in examples_dir.iterdir():\n        if category_dir.is_dir():\n            tools = [f.stem for f in category_dir.glob(\"*.yaml\")]\n            categories[category_dir.name] = sorted(tools)\n    \n    return categories\n```\n\nSTEP 3: Add MCP Resource for On-Demand Tool Loading\n```python\n@mcp.resource(\"thinking-tools://tool-spec/{category}/{tool_name}\")\ndef get_tool_yaml_spec(category: str, tool_name: str) -> str:\n    \"\"\"Get tool YAML specification on-demand.\n    \n    Allows clients to load tool spec only when needed.\n    \"\"\"\n    tool_path = Path(\"examples\") / category / f\"{tool_name}.yaml\"\n    \n    if not tool_path.exists():\n        raise ValueError(f\"Tool {category}/{tool_name} not found\")\n    \n    with tool_path.open() as f:\n        return f.read()\n```\n\nSTEP 4: Update ToolRegistry for Recursive Scanning\n```python\n# In create_server() or module initialization:\ndef get_tool_registry() -> ToolRegistry:\n    if not hasattr(get_tool_registry, \"_registry\"):\n        examples_dir = Path(\"examples\")\n        get_tool_registry._registry = ToolRegistry([examples_dir])\n        # Ensure recursive discovery if not default\n        get_tool_registry._registry.discover_tools()\n    return get_tool_registry._registry\n```\n\nEXPECTED TOKEN SAVINGS:\n- Before: 9 tools × 500 = 4,500 tokens upfront\n- After: ~100 tokens + 500 per tool used\n- Typical (3 tools): 100 + 1,500 = 1,600 tokens\n- SAVINGS: 65% (2,900 tokens)\n\n═══════════════════════════════════════════════════════════\nENHANCEMENT 2: TOKEN USAGE TELEMETRY\n═══════════════════════════════════════════════════════════\n\nRESEARCH FINDING: Multi-agent systems use 15× more tokens. Need empirical data to validate optimizations.\n\nSOLUTION: Simple Token Tracking\n\nSTEP 1: Add Token Tracker Module\n```python\n# Simple tracker at module level\nclass SimpleTokenTracker:\n    def __init__(self):\n        self.operations = []\n    \n    def track(self, operation: str, input_est: int, output_est: int, tool_name: str = None):\n        self.operations.append({\n            \"op\": operation,\n            \"tool\": tool_name,\n            \"in\": input_est,\n            \"out\": output_est,\n            \"total\": input_est + output_est\n        })\n    \n    def summary(self) -> dict:\n        return {\n            \"total_ops\": len(self.operations),\n            \"total_tokens\": sum(op[\"total\"] for op in self.operations),\n            \"breakdown\": self.operations\n        }\n\n_token_tracker = SimpleTokenTracker()\n```\n\nSTEP 2: Add Token Stats Tool\n```python\n@mcp.tool()\ndef get_token_usage_stats() -> Dict[str, Any]:\n    \"\"\"Get token usage statistics for this MCP session.\"\"\"\n    return _token_tracker.summary()\n```\n\nSTEP 3: Add Tracking to Execute Tool\n```python\n@mcp.tool()\ndef execute_thinking_tool(tool_name: str, parameters: Dict[str, Any]) -> str:\n    # Estimate tokens (rough: chars / 4)\n    input_est = len(str(parameters)) // 4\n    \n    result = tool_executor.execute_by_name(tool_name, registry, parameters)\n    \n    output_est = len(result) // 4\n    _token_tracker.track(\"execute_tool\", input_est, output_est, tool_name)\n    \n    return result\n```\n\nNOTE: Estimates are rough (char/4) but sufficient for optimization decisions.\n\n═══════════════════════════════════════════════════════════\nQUALITY GATES\n═══════════════════════════════════════════════════════════\n\n✅ YAML files reorganized into categories\n✅ discover_tool_categories() resource working\n✅ get_tool_yaml_spec() resource working  \n✅ ToolRegistry scans recursively\n✅ Token tracker implemented\n✅ get_token_usage_stats() tool working\n✅ Token tracking in execute_thinking_tool()\n✅ Tests updated for new structure\n✅ All existing tests still pass\n✅ ruff, black, pytest pass (mypy optional given known env issue)\n\n═══════════════════════════════════════════════════════════\nSUCCESS CRITERIA\n═══════════════════════════════════════════════════════════\n\n1. Categories discoverable via thinking-tools://discover\n2. Individual tool specs loadable via thinking-tools://tool-spec/{cat}/{name}\n3. Token usage measurable via get_token_usage_stats()\n4. All existing functionality preserved\n5. Test coverage maintained (≥50%)\n\n═══════════════════════════════════════════════════════════\nREFERENCES\n═══════════════════════════════════════════════════════════\n\n- Filesystem MCP pattern: /c/Development/serena/docs/plans/thinking-tools/research/SKILLS-VS-MCP-ANALYSIS.md\n- Actionable recommendations: /c/Development/serena/docs/plans/thinking-tools/research/ACTIONABLE-RECOMMENDATIONS.md\n- Research synthesis: /c/Development/serena/docs/plans/thinking-tools/research/RESEARCH-SYNTHESIS.md\n\nPROCESS MEMORY:\n- PM-017: JIT learning, 70% token savings (aligns with progressive disclosure)\n- PM-004: Hot-reload support (already achieved with FastMCP)\n\n═══════════════════════════════════════════════════════════\nIMPLEMENTATION NOTES\n═══════════════════════════════════════════════════════════\n\nEFFORT ESTIMATE: 2-3 hours\n- File reorganization: 30 min\n- Progressive discovery resources: 1 hour\n- Token tracker: 1 hour  \n- Testing: 30 min\n\nBACKWARDS COMPATIBILITY:\n- All existing tools work unchanged\n- New resources are optional\n- Token tracking is passive\n\nPROCEED WITH IMPLEMENTATION. Report completion with token savings measured.",
  "references": [
    "layer5-fastmcp-refactor",
    "msg-20251117-090000"
  ],
  "metadata": {
    "task_id": "layer5-progressive-disclosure-telemetry",
    "enhancement_type": "token-optimization-and-telemetry",
    "guide_references": [
      "/c/Development/serena/docs/plans/thinking-tools/research/ACTIONABLE-RECOMMENDATIONS.md",
      "/c/Development/serena/docs/plans/thinking-tools/research/SKILLS-VS-MCP-ANALYSIS.md"
    ],
    "process_memory_refs": ["PM-017", "PM-004"],
    "expected_token_savings": "65%",
    "expected_effort_hours": "2-3",
    "new_capabilities": ["progressive-disclosure", "token-telemetry"]
  },
  "read": false
}
